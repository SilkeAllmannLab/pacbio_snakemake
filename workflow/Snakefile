# Main entrypoint of the workflow. 
# Please follow the best practices: 
# https://snakemake.readthedocs.io/en/stable/snakefiles/best_practices.html,
# in particular regarding the standardized folder structure mentioned there. 

from snakemake.utils import min_version

##### set minimum snakemake version #####
min_version("6.7.0")
import os
import pandas as pd
import sys
sys.path.append("workflow/scripts/")

#################
# PIPELINE CONFIG
#################

configfile: "config/config.yaml"


#########################
# IMPORT USEFUL FUNCTIONS
#########################

#########
# SAMPLES
#########
from common import sample_csv_to_pandas_df

samples_df = sample_csv_to_pandas_df(path_to_sample_csv_file=config["samples"])
SAMPLES = samples_df.index.values.tolist()

#####################
# MAIN INPUT FUNCTION
#####################

def get_subread_file(wildcards):
    subread_bam_file = samples_df.loc[(wildcards.sample), "pacbio"]  
    return subread_bam_file

##############
# TARGET RULES
##############

CCS = expand(config["working_dir"] + "01_css/{sample}.css.bam", sample=SAMPLES)
FL = expand(config["working_dir"] + "02_fl/{sample}.fl.bam", sample=SAMPLES)
FLNC = expand(config["working_dir"] + "03_flnc/{sample}.flnc.bam", sample=SAMPLES)

rule all:
    input:
        FLNC
    message:
        "PacBio IsoSeq Snakemake pipeline successfully run."
        
#######
# RULES
#######

rule generate_circular_consensus_reads:
    input:
        subreads = get_subread_file
    output:
        css = config["working_dir"] + "01_css/{sample}.css.bam"
    message:
        "Generating Circular Consensus (CSS) Reads for {wildcards.sample} from raw IsoSeq subreads"
    params:
        min_accuracy = config["ccs"]["min_accuracy"],
        report_file  = config["working_dir"] + "01_css/{sample}.css_report_txt"
    threads: 20
    conda:
        "envs/pbccs.yaml"
    shell:
        "ccs "
        "--min-rq {params.min_accuracy} "       # minimum predicted accuracy 
        "--report-file {params.report_file} "
        "--num-threads {threads} "   
        "{input.subreads} {output.css}"

rule generate_full_length_reads:
    input:
        css = config["working_dir"] + "01_css/{sample}.css.bam"
    output:
        fl = config["working_dir"] + "02_fl/{sample}.fl.bam" 
    message:
        "Generating Full Length (FL) reads for {wildcards.sample} from CSS reads"
    conda:
        "envs/lima.yaml"
    params:
        barcodes = config["lima"]["barcodes"], # fasta file with adapters (primers + eventual barcodes)
        report_file  = config["working_dir"] + "02_fl/{sample}.lima_report_txt",
        output_file_name = "02_fl/{sample}.fl"
    threads: 20
    shell:
        "lima "
        "--isoseq "
        "--peek-guess "                     # remove spurious false positive
        "--num-threads {threads} "
        "--log-file  {params.report_file} " # Split output by resolved barcode pair name.
        "--split-named "
        "{input} "
        "{params.barcodes} "
        "{output_file_name};
        "mv {output} {params.outfile_prefix} output"
        
rule generate_full_length_non_chimeric_reads:
    input:
        fl = config["working_dir"] + "02_fl/{sample}.fl.isoseq_5p--isoseq_3p.isoseq_5p--isoseq_3p.bam" 
    output:
        flnc = config["working_dir"] + "03_flnc/{sample}.flnc.bam"
    message:
        "Remove polyA and concatemers from full length (FL) reads to generate full length non chimeric reads (FLNC) for {wildcards.sample}"
    params:
        barcodes = config["lima"]["barcodes"], # fasta file with adapters (primers + eventual barcodes)
    conda: 
        "envs/isoseq3.yaml"
    threads: 20
    shell:
        "isoseq3 refine "
        "--require-polya "
        "--num-threads {threads} "
        "{input} "
        "{params.barcodes} "
        "{output} "
        