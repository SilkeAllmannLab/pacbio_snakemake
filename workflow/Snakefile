# Main entrypoint of the workflow. 
# Please follow the best practices: 
# https://snakemake.readthedocs.io/en/stable/snakefiles/best_practices.html,
# in particular regarding the standardized folder structure mentioned there. 

from snakemake.utils import min_version

##### set minimum snakemake version #####
min_version("6.7.0")
import os
import pandas as pd
import sys
sys.path.append("workflow/scripts/")

#################
# PIPELINE CONFIG
#################

configfile: "config/config.yaml"


#########################
# IMPORT USEFUL FUNCTIONS
#########################

#########
# SAMPLES
#########
from common import sample_csv_to_pandas_df

samples_df = sample_csv_to_pandas_df(path_to_sample_csv_file=config["samples"])
SAMPLES = samples_df.index.values.tolist()

##########
# BARCODES
##########

from common import verify_primer_names

#####################
# MAIN INPUT FUNCTION
#####################

def get_subread_file(wildcards):
    subread_bam_file = samples_df.loc[(wildcards.sample), "pacbio"]  
    return subread_bam_file

##############
# TARGET RULES
##############

# with a reference genome, export both annotation (GTF) and collapsed mRNA isoforms
GTFs = expand(config["result_dir"] + "{sample}.collapsed.gtf", sample=SAMPLES)
FASTAs = expand(config["result_dir"] + "{sample}.collapsed.fasta", sample=SAMPLES)

# without a genome reference
# only exports uncollapsed transcripts in FASTA format 
TRANSCRIPTS = expand(config["result_dir"] + "{sample}.transcripts.fasta", sample=SAMPLES)

if config["genome"]["map_to_genome"] == True:
    rule all:
        input:
            GTFs, FASTAs
        message:
            "PacBio IsoSeq Snakemake pipeline successfully run (with genome alignment 'on')."
elif config["genome"]["map_to_genome"] == False:
    rule all:
        input:
            TRANSCRIPTS
        message:
            "PacBio IsoSeq Snakemake pipeline successfully run (genome alignment 'off')."
else:
    print("Please choose either 'True' or 'False' for the genome mapping option.")
        
#######
# RULES
#######

############## 
# COMMON RULES
##############
rule generate_circular_consensus_reads:
    input:
        subreads = get_subread_file
    output:
        css = config["working_dir"] + "01_css/{sample}.css.bam"
    message:
        "Generating Circular Consensus (CSS) Reads for {wildcards.sample} from raw IsoSeq subreads"
    params:
        min_accuracy = config["ccs"]["min_accuracy"],
        report_file  = config["working_dir"] + "01_css/{sample}.css_report_txt"
    threads: 20
    conda:
        "envs/pbccs.yaml"
    shell:
        "ccs "
        "--min-rq {params.min_accuracy} "       # minimum predicted accuracy 
        "--report-file {params.report_file} "
        "--num-threads {threads} "   
        "{input.subreads} {output.css}"

rule generate_full_length_reads:
    input:
        css = config["working_dir"] + "01_css/{sample}.css.bam"
    output:
        fl = config["working_dir"] + "02_fl/{sample}.fl.isoseq_5p--isoseq_3p.bam" 
    message:
        "Generating Full Length (FL) reads for {wildcards.sample} from CSS reads"
    conda:
        "envs/lima.yaml"
    params:
        barcodes = config["lima"]["barcodes"], # fasta file with adapters (primers + eventual barcodes)
        report_file  = config["working_dir"] + "02_fl/{sample}.lima_report_txt",
        temp_filename = config["working_dir"] + "02_fl/{sample}.fl.bam" # only used for lima to work (renamed after job)
    threads: 20
    shell:
        "lima "
        "--isoseq "
        "--peek-guess "                     # remove spurious false positive
        "--num-threads {threads} "
        "--log-file  {params.report_file} " # Split output by resolved barcode pair name.
        "{input} "
        "{params.barcodes} "
        "{params.temp_filename}"
        
rule generate_full_length_non_chimeric_reads:
    input:
        fl = config["working_dir"] + "02_fl/{sample}.fl.isoseq_5p--isoseq_3p.bam"
    output:
        flnc = config["working_dir"] + "03_flnc/{sample}.flnc.bam"
    message:
        "Remove polyA and concatemers from full length (FL) reads to generate full length non chimeric reads (FLNC) for {wildcards.sample}"
    params:
        barcodes = config["lima"]["barcodes"], # fasta file with adapters (primers + eventual barcodes)
        report_file  = config["working_dir"] + "03_flnc/{sample}.isoseq_refine_report_txt"
    conda: 
        "envs/isoseq3.yaml"
    threads: 20
    shell:
        "isoseq3 refine "
        "--require-polya "
        "--num-threads {threads} "
        " --log-file {params.report_file} "
        "{input} "
        "{params.barcodes} "
        "{output} "

rule generate_transcripts_isoforms_using_isoseq:
    input:
        flnc = config["working_dir"] + "03_flnc/{sample}.flnc.bam"
    output:
        transcripts = config["working_dir"] + "04_transcripts/{sample}.transcripts.bam"
    message:
        "Cluster and generate transcript isoforms for {wildcards.sample} using isoseq3"
    params:
        report_file  = config["working_dir"] + "04_transcripts/{sample}.isoseq_cluster_report_txt"
    conda: 
        "envs/isoseq3.yaml"
    threads: 20
    shell:
        "isoseq3 cluster "
        "--num-threads {threads} "
        " --log-file {params.report_file} "
        "--verbose "
        "{input} "
        "{output} "

################################## 
# RULES DEPENDENT ON GENOME OPTION
##################################
if config["genome"]["map_to_genome"] == False:
    rule export_transcripts_to_fasta:
        input: 
            transcripts_bam = config["working_dir"] + "04_transcripts/{sample}.transcripts.bam" 
        output:
            transcripts_fasta = config["result_dir"] + "{sample}.transcripts.fasta"
        message:
            "Exporting {wildcards.sample} transcripts in the {output} file"
        conda:
            "envs/samtools.yaml"
        shell:
            "samtools fasta -o {output} {input}"  

if config["genome"]["map_to_genome"] == True:
    rule generate_genome_index:
        input:
            config["genome"]["genome_fasta_ref"]
        output: 
            config["working_dir"] + "05_minimap/genome.mmi"
        conda:
            "envs/pbmm2.yaml"
        threads: 20
        message:
            "Generate genome index using {input} FASTA file"
        shell:
            "pbmm2 index "
            "--num-threads {threads} "
            "--preset ISOSEQ "
            "{input} "
            "{output}"
    
    rule align_reads_to_genome:
        input:
            genome_index = config["working_dir"] + "05_minimap/genome.mmi",
            transcripts = config["working_dir"] + "04_transcripts/{sample}.transcripts.bam" 
        output:
            aln = config["working_dir"] + "05_minimap/{sample}.aligned.sorted.bam"
        message:
            "Align {wildcards.sample} transcripts to genome reference"
        threads: 20
        conda:
            "envs/pbmm2.yaml"
        shell:
            "pbmm2 align "
            "--preset ISOSEQ " 
            "--sort "
            "--num-threads {threads} "
            "{input.genome_index} "
            "{input.transcripts} "
            "{output}"

    rule collapse_isoforms:
        input:
            aln = config["working_dir"] + "05_minimap/{sample}.aligned.sorted.bam",
            css = config["working_dir"] + "01_css/{sample}.css.bam"
        output:
            gff = config["working_dir"] + "06_gff/{sample}.collapsed.gff",
            fasta = config["result_dir"] + "{sample}.collapsed.fasta"  
        message:
            "Collapse mRNA isoforms of {wildcards.sample} and outputs a GFF and FASTA file"
        conda:
            "envs/isoseq3.yaml"
        params:
            min_aln_coverage = config["isoseq3"]["collapse"]["min_aln_coverage"],
            min_aln_identity = config["isoseq3"]["collapse"]["min_aln_identity"],
            max_fuzzy_junction = config["isoseq3"]["collapse"]["max_fuzzy_junction"]
        shell:
            "isoseq3 collapse "
            "--min-aln-coverage {params.min_aln_coverage} "
            "--min-aln-identity {params.min_aln_identity} "
            "--max-fuzzy-junction {params.max_fuzzy_junction} "
            "{input.aln} "
            "{input.css} "
            "{output.gff}"
    
    rule convert_gff_to_gff:
        input:
            gff = config["working_dir"] + "06_gff/{sample}.collapsed.gff",
        output:
            gtf = config["result_dir"] + "{sample}.collapsed.gtf"
        message:
            "Convert {wildcards.sample} GFF annotation to GTF"
        conda:
            "envs/cufflinks.yaml"
        shell:
            "gffread {input} -T -o {output}"

        
             

